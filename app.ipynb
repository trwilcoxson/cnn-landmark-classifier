{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "## Project: Write an Algorithm for Landmark Classification\n",
    "\n",
    "### Install Prerequisites\n",
    "\n",
    "To run the app in the notebook environment, you must first install the required packages by executing the two cells below. **Make sure to restart the kernel after running each cell.**\n",
    "\n",
    "> Note: Restarting the kernel ensures that all installed dependencies are properly loaded into the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install requirements (skip requirements.txt — we install deps individually for compatibility)\n!pip install livelossplot seaborn pandas tqdm ipywidgets --break-system-packages -q 2>/dev/null || pip install livelossplot seaborn pandas tqdm ipywidgets -q"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please restart the notebook kernel after running this cell as well.\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Simple App\n",
    "\n",
    "In this notebook we build a very simple app that uses our exported model.\n",
    "\n",
    "> <img src=\"static_images/icons/noun-info-2558213.png\" alt=\"?\" style=\"width:25px\"/> Note how we are not importing anything from our source code (we do not use any module from the ``src`` directory). This is because the exported model, differently from the model weights, is a standalone serialization of our model and therefore it does not need anything else. You can ship that file to anybody, and as long as they can import ``torch``, they will be able to use your model. This is very important for releasing pytorch models to production.\n",
    "\n",
    "### Test Your App\n",
    "Go to a search engine for images (like Google Images) and search for images of some of the landmarks, like the Eiffel Tower, the Golden Gate Bridge, Machu Picchu and so on. Save a few examples locally, then upload them to your app to see how your model behaves!\n",
    "\n",
    "The app will show the top 5 classes that the model think are most relevant for the picture you have uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from ipywidgets import VBox, Button, FileUpload, Output, Label\nfrom PIL import Image\nfrom IPython.display import display\nimport io\nimport numpy as np\nimport torchvision\nimport torchvision.transforms as T\nimport torch\n\n# Load the transfer learning model (best performance)\nlearn_inf = torch.jit.load(\"checkpoints/transfer_exported.pt\")\n\ndef on_click_classify(change):\n\n    # Load image that has been uploaded\n    fn = io.BytesIO(btn_upload.data[-1])\n\n    img = Image.open(fn)\n    img.load()\n\n    # Let's clear the previous output (if any)\n    out_pl.clear_output()\n\n    # Display the image\n    with out_pl:\n\n        ratio = img.size[0] / img.size[1]\n        c = img.copy()\n        c.thumbnail([ratio * 200, 200])\n        display(c)\n\n    # Transform to tensor\n    timg = T.ToTensor()(img).unsqueeze_(0)\n\n    # Calling the model\n    softmax = learn_inf(timg).data.cpu().numpy().squeeze()\n    \n    # Get the indexes of the classes ordered by softmax\n    # (larger first)\n    idxs = np.argsort(softmax)[::-1]\n    \n    # Loop over the classes with the largest softmax\n    for i in range(5):\n        # Get softmax value\n        p = softmax[idxs[i]]\n    \n        # Get class name\n        landmark_name = learn_inf.class_names[idxs[i]]\n        \n        labels[i].value = f\"{landmark_name} (prob: {p:.2f})\"\n\n\n# Putting back btn_upload to a widget for next cell\nbtn_upload = FileUpload()\n\nbtn_run = Button(description=\"Classify\")\nbtn_run.on_click(on_click_classify)\n\nlabels = []\nfor _ in range(5):\n    labels.append(Label())\n\nout_pl = Output()\nout_pl.clear_output()\n\nwgs = [Label(\"Please upload a picture of a landmark\"), btn_upload, btn_run, out_pl]\nwgs.extend(labels)\n\nVBox(wgs)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Standalone App or Web App\n",
    "\n",
    "You can run this notebook as a standalone app on your computer by following these steps:\n",
    "\n",
    "1. Download this notebook in a directory on your machine\n",
    "2. Download the model export (for example, ``checkpoints/transfer_exported.pt``) in a subdirectory called ``checkpoints`` within the directory where you save the app.ipynb notebook\n",
    "3. Install voila if you don't have it already (``pip install voila``)\n",
    "4. Run your app: ``voila app.ipynb --show_tracebacks=True``\n",
    "5. Customize your notebook to make your app prettier and rerun voila\n",
    "\n",
    "You can also deploy this app as a website using Binder: https://voila.readthedocs.io/en/stable/deploy.html#deployment-on-binder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2exw58nybf",
   "source": "---\n## Stand Out: Additional Use Cases\n\nA landmark classification model like ours has several practical applications beyond simple identification:\n\n1. **Travel Recommendation Engine:** Given a user's photo library, automatically identify which landmarks they've visited and recommend similar destinations. For example, if someone has photos of European cathedrals, suggest other Gothic architecture sites they haven't visited.\n\n2. **Automatic Photo Tagging & Organization:** Photo management apps (Google Photos, Apple Photos) can use landmark classification to automatically tag and organize travel photos by location, even when GPS metadata is missing or inaccurate.\n\n3. **Heritage Preservation & Monitoring:** Conservation organizations can use landmark classifiers to monitor the condition of cultural heritage sites over time by analyzing crowd-sourced photos, detecting structural changes or damage.\n\n4. **Tourism Analytics:** City planners and tourism boards can analyze social media images to understand visitor patterns — which landmarks are most photographed, peak visiting times, and how tourist interest changes seasonally.\n\n5. **Accessibility for Visually Impaired:** Integrated into assistive technology apps, a landmark classifier could provide real-time audio descriptions for visually impaired travelers, helping them identify and learn about landmarks as they explore a city.\n\n6. **Augmented Reality (AR) Experiences:** AR apps can use landmark detection as a trigger to overlay historical information, virtual reconstructions, or interactive guides when a user points their camera at a recognized landmark.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Your Submission Archive\n",
    "\n",
    "Now that you are done with your project, please run the following cell. It will generate a file containing all the code you have written, as well as the notebooks. Please submit that file to complete your project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python src/create_submit_pkg.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}